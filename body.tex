\title[Volumetric Ray Tracing]%
      {Volumetric Ray Tracing}

% for anonymous conference submission please enter your SUBMISSION ID
% instead of the author's name (and leave the affiliation blank) !!
\author[Matthias Eberhardt]
%{\parbox{\textwidth}{\centering D.\,W. Fellner\thanks{Chairman Eurographics Publications Board}$^{1,2}$
 %      and S. Behnke$^{2}$
 {\parbox{\textwidth}{\centering Matthias Eberhardt$^{1}$
%        S. Spencer$^2$\thanks{Chairman Siggraph Publications Board}
        }
        \\
% For Computer Graphics Forum: Please use the abbreviation of your first name.
{\parbox{\textwidth}{\centering $^1$Ostbayerische Technische Hochschule Regensburg, Germany
%        $^2$ Another Department to illustrate the use in papers from authors
%             with different affiliations
       }
}
}
% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
\volume{2021}   % the volume in which the issue will be published;
\issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}


\maketitle
%-------------------------------------------------------------------------
\begin{abstract}
Volumetric ray tracing comprises different techniques to visualize volumetric data by sending rays within the volume and sampling it at various points. In this paper, we aim to introduce the reader to the mathematical theory of volumetric ray tracing, as well as to provide a detailed description of three basic algorithms that are used to render ambient, direct, and global lighting respectively. Furthermore, we also provide a short description of some more specialized monte carlo ray tracers. At last, we provide the reader with a summary and references to related topics.
\end{abstract}  
%-------------------------------------------------------------------------





%START OF TEXT





\section{Introduction}
In Computer Graphics, objects usually are represented as a set of geometric primitives \cite{KOBBELT2004801} (e.g. triangles), displaying the surface of the object. However, this approach is not always suitable. For example, if the original data representation of the object is volumetric, the traditional rendering technique would necessitate the creation of an intermediate surface representation that might introduce unwanted artifacts\cite{511}. Another issue arises if the object has no well-defined surfaces to which geometric primitives could be fitted, such as a cloud or fog\cite{10.1145/964965.808594}. In such cases, volumetric ray tracing might be used, a technique in which rays are cast through a volume that contains information about its optical properties (e.g color and opacity), sampled at various points within the volume, accumulated, and projected on a 2D image (see figure \ref{fig:simple_algorithm})\cite{511}.
We begin our paper by introducing the reader to the mathematical formalisms of volumetric ray tracing in chapter \ref{sec:math}. In chapter \ref{sec:ray_marching}, we make certain assumptions about the mathematical model that allow us to describe simple volume rendering algorithms by foregoing global illumination. Afterward, we introduce a monte carlo ray tracer, capable of rendering global illumination, as well as the mathematical methods necessary for its formulation. We then present a selection of specialized variants of the monte carlo ray tracer in chapter \ref{sec:mc_algorithms}. In the final chapter \ref{sec:conclusion}, we draw a comparison and provide the reader with references to further work. 




\section{Derivation of the Rendering Equation}
\label{sec:math}
Volumetric ray tracing follows the same principle as classical ray tracing in which an image is rendered by spanning a pixel plane in front of the camera and casting one or multiple rays through each pixel\cite{10.5555/94788}.
That means for a point ${x}$ on the plane we cast a ray in direction $-\omega$ and calculate the amount of light ${x}$ receives from direction $\omega$, called $L({x},\omega )$.
To do this, we find the closest intersection point of the ray with a piece of geometry,  ${y}$,  from where a certain light intensity $L_e({y},\omega )$ is transported in direction $\omega$, either through reflection or emission (The method for calculating $L_e$ is a topic of classical raytracing\cite{10.5555/94788} and $L_e$ is assumed to be a known quantity in this paper).
Thus, we get the equation 

\begin{equation}\label{eq:no_attenuation}
L({x},\omega ) = L_e({y}, \omega )
\end{equation}

\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_interactions.pdf_tex}

\caption{An overview of the possible interactions a light ray can experience in a participating medium. The light might travel through the medium unimpeded (1, e.g. in a clear atmosphere), might be out or in-scattered (2 and 3, e.g. in clouds), or absorbed (4, e.g. in smoke). Additionally, light might be emitted from inside the medium (5, e.g. in a fire).}
\label{fig:light_interactions}
\end{figure}


However, this equation assumes that the light has no interactions between ${x}$ and ${y}$, which is only true if the ray travels through a vacuum. If it travels through a medium that interacts with it (called a participating medium), the interactions change the light along the ray\cite{10.5555/275458.275468} (see figure \ref{fig:light_interactions}). The types of interactions we need to analyze are absorption, emission, in-scattering, and out-scattering\cite{468400}.

Absorption and out-scattering attenuate the light intensity along the ray, whereas in-scattering and emission add to it.
\subsection{Absorption and Out-Scattering}
At first, we evaluate only out-scattering and absorption, which (like in-scattering and emission) occur due to tiny particles suspended in the volume\cite{10.1145/1179352.1141986} (such as water droplets in clouds and fog).
Of course, these particles are far too numerous to be directly simulated, but their distribution in 3D space can be stochastically modeled\cite{10.1145/1179352.1141986} (similar to how detailed surface structures can be modeled by microfacets \cite{10.1145/965141.563893} in surface ray tracing).

\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_cylinder.pdf_tex}

\caption{Image adapted from Max \cite{468400}.}
\label{fig:cylinder}
\end{figure}
We closely follow Max\cite{468400} in the derivation of the stochastical model: Consider a close-up look at a ray section traveling through the volume. This section is modeled as a cylinder with a base area $E$ and a height $\Delta h$ (see figure \ref{fig:cylinder}). Within it, there exists a certain number of out-scattering and absorbing particles, defined as $n_s={\rho}_sE{\Delta}h$ and $n_a={\rho}_aE{\Delta}h$ respectively, where ${\rho}_s$ and ${\rho}_a$ are the densities of the particles. From the top-down view (see figure \ref{fig:projected_cylinder}), the particles occupy an area of ${n_sA}=\frac{{\rho}_sAE{\Delta}h}{E}$ and ${n_aA}=\frac{{\rho}_aAE{\Delta}h}{E}$, respectively, if we posit that the particles do not overlap each other, which is reasonable if the densities and the height do not become too large.



\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_projected_cylinder.pdf_tex}

\caption{Top-down view of the cylinder. A fraction of the base area $E$ is occluded by absorbing and scattering particles. Image inspired by Max \cite{468400}.}
\label{fig:projected_cylinder}
\end{figure}

This simplifies to ${\rho}_aA{\Delta}h$ and ${\rho}_sA{\Delta}h$, giving us the fractions of light stopped in the cylinder through absorption and out-scattering. By letting $\Delta h$ approach 0, we see that for each infinitesimally small cylinder slice with height $dh$, the change in intensity is proportional to $-({\rho}_sA + {\rho}_aA)dh$.
Formulated as a differential equation, this results in
\begin{equation} \label{eq:differential}
dL = -({\rho}_s(h)A + {\rho}_a(h)A)L(h)dh
\end{equation}
As a shorthand, we define the scattering coefficient ${\mu}_s ={\rho}_s(h)A $, the absorption coefficient ${\mu}_a = {\rho}_a(h)A$ and the extinction coefficient ${\mu}_t = {\mu}_s +{\mu}_a$, which give a measure of how much light is lost due to scattering, to absorption, and in total. Thus, equation \ref{eq:differential} simplifies to
\begin{align*}
dL = - {\mu}_t(h)L(h)dh
\end{align*}
which solution is
\begin{align*}
L(h) = L(0)e^{-\int_{0}^{h} {\mu}_t(s)ds}
\end{align*}
Rearranging this results in the equation
\begin{equation} \label{eq:tau_definition}
\frac{L(h)}{L(0)} = e^{-\int_{0}^{h} {\mu}_t(s)ds}
\end{equation}
describing the ratio of the light traveling a distance $h$ unimpeded, the so-called transmittance $\tau$ .
%remove going back to?%
Thus, we can now specify how much $L_e$ gets attenuated:
\begin{align*}
L({x},\omega ) =\tau({x}, {y}) L_e({y}, \omega )
\end{align*}
This equation is still not accurate since we also need to consider in-scattering and emission.
\subsection{Emission and In-Scattering}


\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_light_changes.pdf_tex}

\caption{Simplified illustration of light transport in a participating medium. Light is transported from $y$ to $x$ in direction $\omega$, but is attenuated by $\tau(x,y)$. During the travel, the light ray also receives light, such as at point $u$, which receives some light from $\omega'$, some of which is scattered towards $\omega$. Image adapted from Zhou et al. \cite{zhou2007real-time}.}
\label{fig:light_changes}
\end{figure}


Postulate any arbitrary point ${u}$ on the ray from ${x}$ to ${y}$ (see figure \ref{fig:light_changes}).
At ${u}$, the particles of the medium emit some light towards $\omega$\cite{468400}, which we call $\varepsilon ({u}, \omega )$. In the cylindrical model, the probability of finding an absorbing particle at position ${u}$ is ${\mu}_a({u})$. We assume that the particles responsible for absorption are also responsible for emission\cite{468400}, meaning the amount of light emitted at ${u}$ towards $\omega$ is ${\mu}_a({u})\epsilon ({u}, \omega )$.

In-scattered light can arrive at ${u}$ from every direction, therefore we must integrate over the unit sphere $\Omega$ surrounding ${u}$\cite{10.1145/280814.280925}:
\begin{align*}
\int_{\Omega} L({u}, \omega `)d\omega `
\end{align*}
However, not all light arriving at ${u}$ is scattered towards $\omega $. The phase function $f_p({u}, \omega , -\omega `)$ describes the probality density \cite{wiki:Probability_density_function} that light hitting a particle at ${u}$ from $\omega `$ is reflected towards $\omega$ \cite{10.1145/280814.280925, Cerezo2005}, analogous to the BRDF \cite{10.1145/965141.563893} in surface ray tracing. Furthermore, the amount of light scattered towards $\omega $ also depends on the probability that in-scattering particles are present at ${u}$\cite{10.1145/280814.280925}. Assuming that in and out-scattering particles are the same results in the equation
\begin{align*}
L_e^s({u}, \omega ) = {\mu}_s({u})\int_{\Omega} f_p({u}, \omega , -\omega `)L({u}, \omega `)d\omega `  + {\mu}_a({u})\varepsilon ({u}, \omega )
\end{align*}
which describes the total amount of light being added to the ray at ${u}$.
Not all of $L_e^s({u}, \omega )$ arrives at ${x}$ since the newly added light also needs to travel through the volume, where it is attenuated by the transmittance $\tau ({x}, {u})$.
To get the total light intensity added to the ray, we sum up the light contribution of all points along the ray by integrating over it\cite{zhou2007real-time}:
\begin{align*}
\int_{{x}}^{{y}} \tau({x}, {u})L_e^s({u}, \omega )d{u}
\end{align*}
\subsection{The Rendering Equation}
Adding this to the light arriving from ${y}$ gives the total amount of light arriving at ${x}$ from $\omega $.
\begin{align*}
L({x}, \omega ) = {\int_{{x}}^{{y}} \tau({x}, {u})L_e^s({u}, \omega )d{u}} + \tau({x}, {y}) L_e({y}, \omega )
\end{align*}
This integral is analytically unsolvable in the general case \cite{10.1145/964965.808594}.
In the following, we describe several methods for approximating a solution.











\section{Ray Marching Algorithm}
\label{sec:ray_marching}
In this chapter, we discuss an algorithmic solution\cite{511, 10.1145/147130.147155} to a simplified version of the rendering equation we derived in the previous section.
\subsection{Simplified Rendering Equation}
In the following, we ignore all scattering effects in the medium and suppose that the medium only absorbs and emits light\cite{10.1145/147130.147155}. This can be understood as a scenario where all external light has been evenly distributed within the volume, analogous to only rendering ambient lighting in classical ray tracing, which assumes that the light is evenly distributed in the scene.
Furthermore, we also ignore all other geometry in the scene and only focus on the volume. The term $\tau({x}, {y}) L_e({y}, \omega )$ is therefore omitted.
Thus, we arrive at the equation
\begin{equation} \label{eq:simplified_req}
L({x}, \omega ) = \int_{{x}}^{{y}} \tau({x}, {u}){\mu}_a({u})\epsilon ({u}, \omega)d{u}
\end{equation}
For this chapter, we postulate that the medium is contained within a cuboid boundary\cite{10.1145/147130.147155, 10.1145/78964.78965}. Since there is no geometry, the endpoint $y$ is located where the ray leaves the boundary (see figure \ref{fig:simple_algorithm}).

\subsection{Discrete Approximation to the Simplified Equation}
\label{subsec:discrete_marching}
\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_simple_algorithm.pdf_tex}

\caption{Illustration of the ray marching process. Image adapted from Levoy \cite{10.1145/78964.78965}.}
\label{fig:simple_algorithm}
\end{figure}



$L({x},\omega )$ is approximated by casting a ray in direction $-\omega$ and sampling it at evenly spaced points along the ray (see figure \ref{fig:simple_algorithm}) and summing up their contributions\cite{511}. The distance $s$ between the sampling points should be smaller than the volumes Nyquist limit \cite{659497}, otherwise details are missed \cite{10.1145/2661229.2661292}.
Sampling starts at the first point within the volume, which has a distance of $s_0$ to ${x}$. The $i$-th sample point is described by
\begin{align*}
p_i={x} + s_0(-\omega) + si(-\omega)
\end{align*}
The light contribution of $p_i$ is considered to be the light contribution of the ray segment between $p_{i-1}$ and $p_i$.
\begin{align*}
\int_{p_{i-1}}^{p_i} \tau (p_0,p_{i-1}) \tau(p_{i-1},p_{i}') \mu_a(p_{i}')\varepsilon (p_{i}', \omega)dp_{i}'
\end{align*} 



As a simplification, we assume all variables to be piecewise constant\cite{10.1145/147130.147155} on the ray segments. This yields
\begin{align*}
\tau(p_0, p_i) \mu_a(p_{i})\varepsilon (p_{i}, \omega)s
\end{align*} 


for the light contribution from one line segment between $p_{i-1}$ and $p_i$ with $\tau(p_0, p_i)$ equal to


\begin{equation}\label{eq:discrete_tau_approx}
\tau(p_0, p_i)=\prod_{1\le j \le i}{\tau(p_{j-1}, p_j)}
\end{equation} 



The quantity $\mu_a(p_{i})\varepsilon (p_{i}, \omega)s$ describes the emitted light from $p_i$ and will from now on be referred to as the color $c(i)$. $\tau(p_0, p_i)$ is the total attenuation (transparency) from $p_0$ to $p_i$, $\tau(p_{j-1}, p_j)$ is the attenuation from $p_{j-1}$ to $p_j$ and can be calculated by applying equation \ref{eq:tau_definition}: 


\begin{align*}
\tau(p_{j-1}, p_j) = e^{-s\mu_t(p_j)}
\end{align*}
However, in computer graphics, it is more common to use opacity instead of transparency. Therefore, we refer to $\tau(p_{j-1}, p_j)$ as $1 - \alpha(j)$ from now on, where $\alpha(j)$ is the opacity \cite{10.1145/147130.147155}. Inserting this in equation \ref{eq:discrete_tau_approx} yields 
\begin{equation} \label{eq:discrete_transmittance}
\tau(p_0, p_i)=\prod_{1 \le j \le i} (1 - \alpha(j))
\end{equation}
Again, we can refer to this quantity in terms of opacity rather than transparency by using the equality
\begin{align*}
1 - \beta(i) = \prod_{1 \le j \le i} (1 - \alpha(j))
\end{align*}
where $\beta(i)$ is the accumulated opacity \cite{10.1145/147130.147155} between ${x}$ and $p_i$.
Using these results, we approximate the integral in equation \ref{eq:simplified_req} as the sum
\begin{equation} \label{eq:discrete_approximation}
L({x},\omega) = \sum_{1 \le i \le n}(1 - \beta(i))c(i)
\end{equation}
which can be calculated in a single for loop\cite{10.1145/147130.147155}.


\subsection{Underlying Volume Data}
Due to our postulation that the variables $\mu_s$, $\mu_a$, $\mu_t$, and $\varepsilon$ are piecewise constant, opacity and color can easily be computed, if the volume provides such information. If the volume is already defined in terms of color and opacity $\alpha$ and $c$ can be sampled directly from it.
In some cases, the volume might contain other information such as density (e.g. for medical 3D scans), in which case a preprocessing step\cite{511} is necessary.
If the volume is defined as a ternary function, sampling is straightforward. If the volume is defined as a 3D array of voxels, the value must be found through interpolation (usually trilinear interpolation\cite{511}).
When interpolating color, $c$ must be weighted with its associated opacity\cite{729595}.

\subsection{Direct Illumination}\label{subsec:direct_illumination}
Until now, we have ignored scattering in the ray marching algorithm. In the following, we describe an approach to simulate single scattering (light rays scattered only once) developed by Kajiya and Von Herzen\cite{10.1145/964965.808594} based on the work of Blinn\cite{10.1145/965145.801255}.
This works as a two-step process.
The first step is computed on a volume $\mathcal{V}$ containing opacity and albedo information and on a set of light sources $\{l_1, \ldots, l_m\}$.
Based on $\mathcal{V}$, one discrete volume $\mathcal{V}'_k$ is created for every light source $l_k$ in the following manner:
For a voxel ${x}$ in $\mathcal{V}'_k$ and light source $l_k$ the amount of light ${x}$ receives from $l_k$ is calculated by attenuating the emmited light $\varepsilon(l_k)$ by the transmittance $\tau({x}, l_k) = \int_{{x}}^{l_k}(1 - \alpha({x'}))d{x'}$. This is computed as described above in equation \ref{eq:discrete_transmittance}.
 The albedo $a({x})$ regulates how much of the arriving light is reflected at ${x}$. Thus, the color of ${x}$ is
\begin{align*}
c_k({x}) = a({x}) \tau({x}, l_k) \varepsilon(l_k)
\end{align*}
In other words, the volume $\mathcal{V}'_k$ contains the light that is reflected from $l_k$ at every voxel.

The second step works very similar to ray marching as described by equation \ref{eq:discrete_approximation}, with the only difference being the calculation of $c(i)$. For this, the values of $c_k(p_i)$ needs to be known for all $k$, which can be calculated by sampling and interpolating in $\mathcal{V}'_k$.
$c_k(p_i)$ is the light intensity reflected at $p_i$, but only a portion is reflected towards $\omega$. By scaling all $c_k$ by the phase function and summing up their contribution, we define $c(i)$ as
\begin{align*}
c(i) = \sum_{1 \le k \le m} f_p(\omega, -\omega_k, p_i)c_k(p_i)
\end{align*}
with $\omega_k$ being the direction from $l_k$ to $p_i$ ($\omega_k$ is different for every $l_k$, which is the reason the different $c_k$ are stored seperately).


This algorithm is an improvement to the one described in chapter \ref{subsec:discrete_marching}, but still suffers from problems such as increased computational complexity, inability to render volumes with high albedo \cite{10.1145/964965.808594} and its bias\cite{10.1145/3451256}. While certain optimizations concerning computational speed have been developed\cite{10.1145/78964.78965, 10.1145/147130.147155}, rendering photorealistic images requires more sophisticated techniques.










\section{Monte Carlo Ray Tracing and Global Illumination}
\label{sec:mc}
A common technique in classical ray tracing to generate unbiased images with global illumination so-called monte carlo ray tracing (MCRT) approach \cite{mc_siggraph} which estimates the rendering equation by stochastically sampling it.

In this chapter, we explain a standard MCRT and explain certain techniques necessary for its formulation.
\subsection{General Monte Carlo Algorithm}
This chapter describes a typical MCRT such as that used by Hofman et al. \cite{10.1145/3451256}.
The algorithm starts by casting a ray from the camera $p_0$ in direction $-\omega_0$. Then, a distance $d_0$ is sampled stochastically and a so-called path vertex $p_1$ is created. From $p_1$, a new direction $\omega_1$ is sampled. This process is repeated until a light source is hit or until the path gets terminated (usually by Russian roulette \cite{P-766}). Furthermore, at every path vertex $p_i$, a so-called next event estimation \cite{10.1145/3305366.3328079} is done by casting a shadow ray towards a randomly sampled point on a light source $l_i$. Then, the light contributions along the path are properly weighted \cite{10.1145/218380.218498} and summed up to compute the final result.
An illustration of the process can be seen in figure \ref{fig:monte_carlo}.


\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_monte_carlo.pdf_tex}

\caption{Illustration of monte carlo path tracing. Image inspired by Galtier at al. \cite{GALTIER201357} and Lafortune and Willems \cite{bidirectional-ray-tracing}}
\label{fig:monte_carlo}
\end{figure}


For the algorithm, the following quantities need to be known: The transmittance $\tau$ between the various path vertices and light sources, the directions $\omega_i$, and the locations of $l_i$ and $p_i$.
The sampling of $\omega_i$ and $l_i$ works like in classical ray tracing, using multiple importance sampling\cite{10.1145/218380.218498} of the phase function and light distribution. Sampling $p_i$ and estimating the transmittance require approaches not used in normal ray tracing, two of which are described below. 
\subsection{Delta Tracking}
To calculate $p_{i+1} = p_i - \,\omega t_i$ from a given $p_i$ and $\omega_i$, the distance $t_i$ between those two points must be sampled. Recall that $\tau(p_i, p_{i+1})$ describes the ratio of light arriving from $p_{i+1}$ at $p_i$ without colliding with a particle. Therefore, the probability density \cite{wiki:Probability_density_function} that a collision occurs between $p_i$ and $p_{i+1}$ is 
\begin{equation} \label{eq:collision_p}
1 - \tau({p_i, p_{i+1}})
\end{equation}
which is also the probability density of $t_i$.
This can be used to importance sample \cite{osti_4167844} the distance $t_i$ by inverting equation \ref{eq:collision_p} and applying the resulting function to $\xi$  (a random variable uniformly sampled from $[0,1]$). However, $\tau$ is defined as $e^{-\int_{0}^{t_i}\mu_t(s)ds}$, which can't be easily inverted if the medium is heterogeneous.
Delta tracking (also known as woodcock tracking) solves this problem by introducing so-called fictitious particles, which neither scatter nor absorb light rays \cite{10.1145/2661229.2661292}. Their distribution $\mu_f$ is chosen so that the sum of $\mu_t$ and $\mu_f$ add up to a globally constant value, the so-called majorant $\overline{\mu}$.
The original problem of finding a real collision is then reformulated to finding any collision (fictitious or real).
Since $\overline{\mu}$ is homogenous, equation \ref{eq:collision_p} can easily be inverted \cite{morgan-delta-tracking} and we get
\begin{align*}
t_i^1 = - \frac{ln(1 - \xi)}{\overline{\mu}}
\end{align*} 
as the sampled distance to the next collision, which might be with a real or a fictitious particle (a so-called null collision).
At position $p_i^1 = p_i - \omega_i t_i^1$, the probability of hitting a real particle is 
\begin{align*}
\mathds{P}(``\text{real collision}``) = \frac{\mu_t(p_i^1)}{\overline{\mu}}
\end{align*}
We decide if a real particle has been hit by sampling another $\xi$ and comparing it to $\mathds{P}(``\text{real collision}``)$. If $\xi$ is smaller, a real particle has been hit, if not, there is a null collision \cite{10.1145/2661229.2661292}.
In this case, we repeat the process and continue to sample distances $t_i^j$ (illustrated in figure \ref{fig:delta_tracking}) from the point $p_i ^{j-1}$ until a real collision at $p_i^n$ is detected. Its distance to $p_i$ is then the sum of all distances previously computed:
\begin{align*}
t_i = \sum_{1 \le j \le n} t_i^j
\end{align*}
The real collision is then selected as the path vertex $p_{i+1}$.


\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_delta_tracking.pdf_tex}

\caption{Delta tracking follows the ray in direction $-\omega_i$ and samples collision points. The first real collision is the position of the next path vertex. Image adapted from Galtier et al. \cite{GALTIER201357}.}
\label{fig:delta_tracking}
\end{figure}

\begin{comment}
Delta tracking can also be used to estimate the transmittance $\tau$ between two points $p'$ and $p - \omega t$\cite{10.1145/2661229.2661292} \cite{10.1145/2661229.2661292}. This is done by using delta tracking to find a real collision on the ray from $p$ to $p'$. If this collision occurs before $p'$, $\tau$ is assumed to be 0, if the collision occurs after $p'$, $\tau$ is estimated as 1 (see figure \ref{fig:delta_tracking_distance}). However, there exist other, more sophisticated methods for estimating transmittance, such as ratio tracking.

\begin{figure}

\fontsize{7}{9}\selectfont
    \def\svgwidth{.48\columnwidth}
    \import{figures/}{fig_delta_tracking_distance_a.pdf_tex}
    \hfill
    \def\svgwidth{.48\columnwidth}
    \import{figures/}{fig_delta_tracking_distance_b.pdf_tex}


\caption{Estimation of transmittance by delta tracking. On the left, the first real collision takes place after $p'$. Thus, $\tau$ is estimated as 1. On the right, a real collision happens before $p'$, and $\tau$ is estimated as 0. Image inspired by Galtier et al. \cite{GALTIER201357}.} \label{fig:delta_tracking_distance}
\end{figure}
\end{comment}

\subsection{Ratio Tracking}
Ratio tracking \cite{10.1145/2661229.2661292} is used to estimate the transmittance between two already known points $p$ and $p'$. This is done by calculating various collision points between $p$ and $p'$, as described above, and stops once a collision point behind $p'$ is found. At each collision point $p^i$, the value $1 - \frac{\mu_t(p^i)}{\overline{\mu}}$ is saved. This fraction between fictitious particles and all particles describes the probability, that a light ray can pass $p^i$ without real collision \cite{10.1145/2661229.2661292}. The transmittance $\tau$ can then be estimated as 
\begin{align*}
\tau(p,p') = \prod_{1 \le i \le n}(1 - \frac{\mu_t(p^i)}{\overline{\mu}})
\end{align*}
where $n$ is the index of the last collision found before $p'$.

\section{Selection of Various Global Illumination Algorithms}
\label{sec:mc_algorithms}
In this chapter, we present a brief overview of global illumination algorithms. For more details, we refer the reader to the sources.
\subsection{Metropolis Light Transport}
Metropolis light transport\cite{metropolis} operates by creating multiple paths from one initial path $\mathcal{P}_0$ consisting of several path vertices, by consecutively mutating path $\mathcal{P}_i$ to get $\mathcal{P}_{i+1}$. The mutations (such as adding or deleting vertices) might be rejected, if the new path does not contribute much light to the final image \cite{metropolis}. An extension to this algorithm for handling participating media has been proposed by Pauly et al. \cite{10.1007/978-3-7091-6303-0_2}.
\subsection{Bidirectional Path Tracing}
Bidirectional path tracing is a technique originally developed for surface rendering \cite{bidirectional-ray-tracing}. The algorithm works by not only tracing paths starting from the camera but also starting from the light (see figure \ref{fig:bidirectional}). Each vertex of the camera path then sends shadow rays to each vertex on the light path. An extension of the algorithm for rendering scenes with participating media has been presented by Lafortune and Willems \cite{10.5555/275458.275468}. The algorithm is particularly well suited for scenes with significant indirect illumination.
\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\import{figures/}{fig_bidirectional.pdf_tex}

\caption{Illustration of bidirectional path tracing. Image adapted from Lafortune and Willems\cite{10.5555/275458.275468}.}
\label{fig:bidirectional}
\end{figure}
\subsection{Photon Mapping}
Photon mapping is a two-pass process \cite{10.1145/280814.280925}, conceptionally similar to the approach described in chapter \ref{subsec:direct_illumination}. Originally developed for surface rendering\cite{10.5555/275458.275461}, its first step is the computation of two photon maps\cite{10.1145/280814.280925} (one for lower frequency global lighting, and one for light that traveled on paths that were reflected by specular surfaces). In the second pass, the image is rendered by tracing paths from the camera into the scene and querying the photon maps for nearby photons.
Jensen and Christensen \cite{10.1145/280814.280925} extended this method to participating media by introducing volumetric photon maps (which differ from the volumes $\mathcal{V}'_k$ described in \ref{subsec:direct_illumination}, as they are not discrete and consider global illumination). These photon maps are computed by tracing rays from the light sources and storing the positions of interactions of those rays with the participating medium.
\subsection{Compensated Ray Marching}
This algorithm, developed by Zhou et al. \cite{zhou2007real-time} follows the same idea as photon mapping but computes its photon distribution on an approximation of the original volume.
In a preprocessing step, the original volume $\mathcal{V}$ is split into a volume $\widetilde{\mathcal{V}}$ and a residual volume $\mathcal{R} = \mathcal{V} - \widetilde{\mathcal{V}}$. $\widetilde{\mathcal{V}}$ is a low frequency approximation to $\mathcal{V}$ and $\mathcal{R}$ is its error. The global lighting is calculated on $\widetilde{\mathcal{V}}$ and is afterward rendered using ray marching (similarly as in \ref{sec:ray_marching}). During the ray marching $\mathcal{R}$ is used to compensate for errors in $\widetilde{\mathcal{V}}$. This is done by increasing the contribution of rays that travel through areas where $\widetilde{\mathcal{V}}$ overestimates the opacity $\mathcal{V}$. This overestimation makes the rays appear darker than they should, and the increase compensates for that.The same is done if $\widetilde{\mathcal{V}}$ underestimates $\mathcal{V}$. $\mathcal{R}$ is used to determine this misestimation. 
It should be emphasized that the rendering step uses ray marching similar as described in chapter \ref{sec:ray_marching} and is therefore biased. 
\section{Conclusion}
\label{sec:conclusion}
In this chapter, we evaluate the presented algorithms and briefly discuss their strength and weaknesses. Furthermore, we provide the reader with an overview of various other approaches to volume rendering and classify the here presented algorithms within that context.
\subsection{Evaluation}
The ray marching algorithms described in chapter \ref{sec:ray_marching} are conceptionally simpler but are incapable of supporting global illumination. In certain use cases, they might be preferable to more advanced algorithms, such when visualizing technical data (e.g a medical 3D scan), where sophisticated lighting is unnecessary, or when rendering objects with low albedo, where global illumination does not contribute much \cite{10.1145/964965.808594}. Of the algorithms described in chapter \ref{sec:mc_algorithms}, Metropolis light transport and bidirectional path tracing are particularly suited for scenes with much indirect lighting \cite{metropolis, bidirectional-ray-tracing}. Photon maps are very efficient in their memory usage \cite{10.1145/280814.280925}. Compensated ray marching is reported to render in real-time \cite{zhou2007real-time}. All the described monte carlo algorithms have the advantage of being unbiased.
\subsection{Classification and Further Work}
On the most basic level volume rendering can be divided into direct and indirect rendering\cite{Westover1991SplattingAP, 4384237}. Indirect rendering requires a pre-processing step to create intermediate surface data, which then is rendered in a second step.
Direct algorithms (which include all algorithms presented in this paper) work directly on the volume data and can be further subdivided into feed-forward and feed-backward methods. Feed-forward methods work by starting with data and determining how much each data point contributes to the final image \cite{10.5555/94788} (e.g. by tracing paths from the light towards the camera), whereas feed-backward algorithms work the opposite way. Photon mapping and bidirectional path tracing are hybrid methods of the algorithms presented in this paper while the others are feed-backward.
Another possibility to classify rendering algorithms is between stochastic and deterministic ones. Of the presented examples, the ray marching and the compensated ray marching are deterministic, the others stochastic. 
An overview of the various methods is provided by Marmitt et al. \cite{Marmitt2006InteractiveVR}, Huang et al. \cite{4384237} and Raab et al. \cite{10.1007/978-3-540-74496-2_35}.




\bibliographystyle{eg-alpha-doi}
\bibliography{bib}



%-------------------------------------------------------------------------
% bibtex
%\bibliographystyle{eg-alpha-doi} 
%\bibliography{bib}       

% biblatex with biber
%\printbibliography                

%-------------------------------------------------------------------------


