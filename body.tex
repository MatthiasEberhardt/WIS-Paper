\title[EG \LaTeX\ Author Guidelines]%
      {Volumetric Ray Tracing}

% for anonymous conference submission please enter your SUBMISSION ID
% instead of the author's name (and leave the affiliation blank) !!
\author[1062]
%{\parbox{\textwidth}{\centering D.\,W. Fellner\thanks{Chairman Eurographics Publications Board}$^{1,2}$
 %      and S. Behnke$^{2}$
 {\parbox{\textwidth}{\centering 1062$^{1}$
%        S. Spencer$^2$\thanks{Chairman Siggraph Publications Board}
        }
        \\
% For Computer Graphics Forum: Please use the abbreviation of your first name.
{\parbox{\textwidth}{\centering $^1$OTH Regensburg, Germany
%        $^2$ Another Department to illustrate the use in papers from authors
%             with different affiliations
       }
}
}
% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
\volume{2021}   % the volume in which the issue will be published;
\issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}


\maketitle
%-------------------------------------------------------------------------
\begin{abstract}

\end{abstract}  
%-------------------------------------------------------------------------
---START OF REVIEW---
\section{Introduction}
In Computer Graphics, objects usually are represented as a set of geometric primitives ( e.g. triangles), displaying the surface of the object in question. However, this approach is not always suitable. For example, if the original data representation of the object is volumetric data (which might be produced by medical 3d scans\cite{511}), the traditional rendering technique would necessitate the creation of an intermediate surface representation that might introduce unwanted artifacts. Another issue arises if the object has no well-defined surfaces to which geometric primitives could be fitted, such as a cloud\cite{10.1145/964965.808594}. In such cases, volumetric ray tracing might be used, a technique in which rays are cast through a volume which contains information about color and opacity, sampled at various points within the volume, accumulated and projected on a 2d image (see figure 1)\cite{511}. A description of this algorithm is presented in this paper, alongside several strategies for improving computational speed, such as (probabilistic) early termination of a ray, and sampling at lower resolutions within the volume.

\begin{figure}[htb]
  \centering
  % the following command controls the width of the embedded file
  % (relative to the width of the current column)
  %\includegraphics[width=.8\linewidth,natwidth=250,natheight=134]{RayCasting1.png}
  \includegraphics[width=.8\linewidth]{RayCasting1.png}
  \parbox[t]{.9\columnwidth}{\relax}~\cite{Appa2015RayCF}
  %
  \caption{\label{fig:firstExample}
          Illustration of the ray casting process.}
\end{figure}

\section{Basic Volumetric Ray Tracing Algorithm}
\subsection{Underlying Volume Data}
In this paper, we consider the topic of synthesizing a 2d image from a 3d volume.
A volume can either be some continuous, ternary function (such as perlin or simplex noise\cite{10.1145/325165.325247}, which can be used to render volumetric clouds\cite{haggstrom2018real}), or a discrete 3d array\cite{511}.
Similar to a 2d image that consists of pixels that can be addressed by a 2d vector $\vec{x} \in \mathbb{N}^2$, a 3d array consits of voxels that are adressed by a 3d vector $\vec{x} \in \mathbb{N}^3$. The color of a voxel at position $\vec{x}$ is called $c(\vec{x})$, the opacity $\alpha(\vec{x})$. The opacity is a scalar value, the color may also be a scalar value (for grayscale volumes) or a 3d vector (for colorful volumes). In the following, all values are assumed to be normalized to between 0 and 1. To project this volume to a image, for each pixel in the image a ray is cast through the volume and sampled at multiple, evenly spaced points on the ray (see figure 1)\cite{10.1145/78964.78965}.
\subsection{Interpolation}
The sample points on the ray are in general part of $\mathbb{R}^3$. This is no problem if the volume is described by a continuous function, which is defined everywhere. However, if it is a discrete 3d array only defined for points in $\mathbb{N}^3$, the value of the volume at the sample point must be interpolated.
 This interpolation is done over the 8 closest voxels to the sample point (usually with a trilinear interpolation). The opacity values can be interpolated regularly, but the color values must be weighted with the respective opacity values before interpolation \cite{729595}. To see why this is necessary, consider figure 2, which presents a simplified 2d example of a completely  opaque, white object behind completely transparent empty space. Naively interpolating in this volume would result in two sample points, one completely white and opaque, the other gray and semitransparent. This gray point is not present in the original data and is an unwanted artifact. Weighting the colors with their opacity prevents this from happening.
 \begin{figure}[htb]
  \centering
  % the following command controls the width of the embedded file
  % (relative to the width of the current column)
  %\includegraphics[width=.8\linewidth,natwidth=250,natheight=134]{RayCasting1.png}
  \includegraphics[width=.8\linewidth]{weighted_interpolation.png}
  \parbox[t]{.9\columnwidth}{\relax}
  %
  \caption{\label{fig:firstExample}
          Simplified visualization of naive interpolation in 2 dimensions. The black dots represent the voxels, the red dots the sample points. Notice that the second sample point has a gray color, even though the original data only has white voxels and blck, transparent voxels, which shouldn't affect the final color. Adapted from Wittenbrink et al.\cite{729595}}
\end{figure}
 \subsection{Compositing Of Multiple Sample Points}
To compose the various sampled points on the ray to a single pixel, the points one after the other are alpha blended together. This compositing can be done front to back\cite{Sabella1988ARA, Upson1988VbufferVV } (starting with the sample point closest to the camera, blending it with the second, then the third, and so on), or back to front\cite{10.1145/378456.378484, 511} (vice versa).  Usually, the back to front approach is chosen since it allows to optimize the computation\cite{10.1145/78964.78965} (see below).
 In the following, $c(i)$ is the color of the i-th sample point, and $\alpha(i)$ the opacity. The accumulated opacity 
 \begin{equation}
 \beta(i) = 1 - \prod_{j=1}^{i}(1 - \alpha(j))
 \end{equation}
 is the fraction of light absorbed between the first and i-th sample point. The final color $c_f$, which is displayed in the projected image, is then
 \begin{equation}
 c_f = \sum_{i=1}^n((1-\beta(i)) * c(i))
 \end{equation}
 if the ray has n sample points\cite{10.1145/147130.147155}.
\section{Optimization Strategies}
\subsection{Adaptive Termination Of Ray Tracing}
When looking at the compositing process described above, it becomes apparent that the contribution of a sample point to the final result decreases, the more other opaque sample points lie before it\cite{10.1145/78964.78965}. For an extreme example, consider figure 3. Here, all sample points behind the fully opaque black wall contribute nothing to the final value and can therefore be ignored. In other words, going back to equation (2), the ray casting can be terminated after the accumulated opacity reaches 1, without changing the image quality. If some errors in the image are acceptable, the threshold value for terminating the ray tracing might be chosen to be somewhat lower.
 \begin{figure}[htb]
  \centering
  % the following command controls the width of the embedded file
  % (relative to the width of the current column)
  %\includegraphics[width=.8\linewidth,natwidth=250,natheight=134]{RayCasting1.png}
  \includegraphics[width=.8\linewidth]{wall.png}
  \parbox[t]{.9\columnwidth}{\relax}
  %
  \caption{\label{fig:firstExample}
         The black, opaque object blocks parts of the volumes behind it. The samples behind the object (from the cameras perspective) are not visible and therefore irrelevant. }
\end{figure}
\subsection{Ray Termination With Russian Roulette}
The above described termination after a certain threshold is reached creates a bias in the synthesized image\cite{10.1145/97880.97886}. One way to avoid this is to use Russian Roulette to decide when to terminate a ray\cite{10.1145/147130.147155}. Unlike the above described approach, Russian Roulette terminates a ray only with a certain likelihood once the accumulated opacity reaches the threshold. The weight of the surviving rays is increased proportionally to compensate for the terminated rays.

\subsection{Pyramid Data Structures}
The following optimizations require a data structure called a pyramid\cite{10.1145/147130.147155}. Similar to a set of mip-maps with decreasing resolutions, a pyramide is a set of 3d arrays with decreasing resolutions. The different volumes of which the pyramid consists are called the levels of the pyramid. The lowest level (called level 0) is equal to the original volume. In general, level $n + 1$ is half the size of level $n$, and each voxel in level $n+1$ contains some information about 8 voxels in the lower volume\cite{10.1145/78964.78965}. What information exactly is stored in the levels contains on what specific pyramid is used, of which there are multiple kinds. The first one is the so called average pyramid, which,as the name suggets, stores the average of the 8 lower voxels in each voxel of the higher level (see figure 4).

 \begin{figure}[htb]
  \centering
  % the following command controls the width of the embedded file
  % (relative to the width of the current column)
  %\includegraphics[width=.8\linewidth,natwidth=250,natheight=134]{RayCasting1.png}
  \includegraphics[width=.8\linewidth]{pyramide.png}
  \parbox[t]{.9\columnwidth}{\relax}
  %
  \caption{\label{fig:firstExample}
         Simplified 2 dimensional example of 2 levels of a pyramid. Each pixel in level n +1 contains 4 pixel of the lower level. In 3 dimensions, 8 voxels of the lower level are contained in one voxel of the upper level.}
\end{figure}
---END OF REVIEW---
\subsection{Presence Acceleration}
%-------------------------------------------------------------------------






\bibliographystyle{eg-alpha-doi}
\bibliography{bib}



%-------------------------------------------------------------------------
% bibtex
%\bibliographystyle{eg-alpha-doi} 
%\bibliography{bib}       

% biblatex with biber
%\printbibliography                

%-------------------------------------------------------------------------


